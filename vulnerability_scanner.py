"""
Vulnerability Scanner for AI Code Translator

This module provides code vulnerability scanning capabilities
that integrate with the MCP server.
"""

import os
import re
import json
import logging
from typing import Dict, List, Any, Optional
import google.generativeai as genai

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("vulnerability_scanner.log", encoding="utf-8"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class VulnerabilityScanner:
    """
    Scans code for security vulnerabilities and suggests fixes.
    """
    
    def __init__(self, api_key: Optional[str] = None, model_name: str = "models/gemini-1.5-pro"):
        """
        Initialize the vulnerability scanner.
        
        Args:
            api_key: The API key for the Gemini API. If None, will try to get from environment.
            model_name: The name of the model to use.
        """
        self.api_key = api_key or os.environ.get("GEMINI_API_KEY")
        if not self.api_key:
            raise ValueError("Gemini API key is required")
        
        # Configure the Gemini API
        genai.configure(api_key=self.api_key)
        
        # Initialize the model
        self.model_name = model_name
        self.model = genai.GenerativeModel(model_name)
        logger.info(f"Initialized vulnerability scanner with model: {model_name}")
        
        # Common vulnerability patterns by language
        self.vulnerability_patterns = {
            "python": [
                r"eval\s*\(",  # Dangerous eval
                r"exec\s*\(",  # Dangerous exec
                r"os\.system\s*\(",  # Command injection
                r"subprocess\.call\s*\(",  # Command injection
                r"__import__\s*\(",  # Dynamic imports
                r"pickle\.loads\s*\(",  # Insecure deserialization
                r"yaml\.load\s*\([^,]",  # YAML injection (without safe loader)
                r"request\.form\s*\[",  # Unvalidated form input
                r"request\.args\.get\s*\(",  # Unvalidated URL parameters
                r"open\s*\([^,]*,\s*['\"]w['\"]",  # Unsafe file write
            ],
            "javascript": [
                r"eval\s*\(",  # Dangerous eval
                r"Function\s*\(",  # Dynamic function creation
                r"document\.write\s*\(",  # XSS vulnerability
                r"innerHTML\s*=",  # XSS vulnerability
                r"localStorage\.(get|set)Item",  # Insecure storage
                r"exec\s*\(",  # Command injection
                r"child_process",  # Command injection
                r"dangerouslySetInnerHTML",  # React XSS vulnerability
                r"fetch\s*\(",  # Potential CSRF
                r"new RegExp\s*\(",  # Potential ReDoS
            ],
            "java": [
                r"Runtime\.getRuntime\(\)\.exec\s*\(",  # Command injection
                r"ProcessBuilder",  # Command injection
                r"System\.exit\s*\(",  # Denial of service
                r"\.readObject\s*\(",  # Insecure deserialization
                r"Class\.forName\s*\(",  # Unsafe reflection
                r"java\.sql\.Statement",  # SQL injection
                r"getParameter\s*\(",  # Unvalidated input
                r"new File\s*\(",  # Unsafe file operations
                r"\.printStackTrace\s*\(",  # Information leakage
                r"\.createStatement\s*\(",  # SQL injection
            ]
        }
    
    def _quick_scan(self, code: str, language: str) -> List[Dict[str, Any]]:
        """
        Perform a quick scan using regex patterns.
        
        Args:
            code: The code to scan.
            language: The programming language.
            
        Returns:
            A list of potential vulnerabilities.
        """
        language = language.lower()
        
        # Default to python patterns if language not supported
        patterns = self.vulnerability_patterns.get(language, self.vulnerability_patterns["python"])
        
        vulnerabilities = []
        lines = code.split('\n')
        
        for pattern in patterns:
            for i, line in enumerate(lines):
                matches = re.findall(pattern, line)
                if matches:
                    vulnerabilities.append({
                        "line": i + 1,
                        "code": line.strip(),
                        "pattern": pattern,
                        "severity": "medium",
                        "type": self._get_vulnerability_type(pattern)
                    })
        
        return vulnerabilities
    
    def _get_vulnerability_type(self, pattern: str) -> str:
        """
        Get the vulnerability type based on the pattern.
        
        Args:
            pattern: The regex pattern.
            
        Returns:
            The vulnerability type.
        """
        if "eval" in pattern or "exec" in pattern:
            return "Code Injection"
        elif "system" in pattern or "subprocess" in pattern or "ProcessBuilder" in pattern:
            return "Command Injection"
        elif "innerHTML" in pattern or "document.write" in pattern:
            return "Cross-Site Scripting (XSS)"
        elif "Statement" in pattern or "createStatement" in pattern:
            return "SQL Injection"
        elif "pickle" in pattern or "readObject" in pattern:
            return "Insecure Deserialization"
        elif "open" in pattern or "File" in pattern:
            return "Unsafe File Operations"
        elif "request" in pattern or "getParameter" in pattern:
            return "Unvalidated Input"
        else:
            return "Potential Security Issue"
    
    def _deep_scan(self, code: str, language: str, quick_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Perform a deep scan using Gemini AI.
        
        Args:
            code: The code to scan.
            language: The programming language.
            quick_results: Results from the quick scan.
            
        Returns:
            Detailed vulnerability analysis.
        """
        # Create a prompt for the AI
        quick_findings = ""
        if quick_results:
            quick_findings = "Initial scan found these potential issues:\n"
            for vuln in quick_results:
                quick_findings += f"- Line {vuln['line']}: {vuln['type']} - {vuln['code']}\n"
        
        prompt = f"""Analyze this {language} code for security vulnerabilities:

```{language}
{code}
```

{quick_findings}

Please provide a detailed security analysis including:
1. Identified vulnerabilities (with line numbers and severity)
2. Explanation of each vulnerability
3. Suggested fixes for each issue
4. Overall security score (0-10)
5. General security recommendations

Format your response as a structured analysis.
"""
        
        try:
            response = self.model.generate_content(prompt)
            return {
                "ai_analysis": response.text,
                "quick_scan_results": quick_results
            }
        except Exception as e:
            logger.error(f"Error in deep scan: {e}")
            return {
                "ai_analysis": f"Error performing deep scan: {str(e)}",
                "quick_scan_results": quick_results
            }
    
    def scan_code(self, code: str, language: str, scan_depth: str = "full") -> Dict[str, Any]:
        """
        Scan code for vulnerabilities.
        
        Args:
            code: The code to scan.
            language: The programming language.
            scan_depth: The scan depth ('quick' or 'full').
            
        Returns:
            The scan results.
        """
        try:
            # Normalize language
            language = language.lower()
            
            # Perform quick scan
            quick_results = self._quick_scan(code, language)
            
            # Return quick results if that's all that was requested
            if scan_depth.lower() == "quick":
                return {
                    "success": True,
                    "vulnerabilities_found": len(quick_results),
                    "results": quick_results,
                    "scan_type": "quick"
                }
            
            # Perform deep scan
            deep_results = self._deep_scan(code, language, quick_results)
            
            return {
                "success": True,
                "vulnerabilities_found": len(quick_results),
                "results": deep_results,
                "scan_type": "full"
            }
            
        except Exception as e:
            logger.error(f"Error scanning code: {e}")
            return {"success": False, "message": f"Error: {str(e)}"}

# Example usage
if __name__ == "__main__":
    # This code runs when the module is executed directly
    try:
        # Initialize the scanner
        api_key = os.environ.get("GEMINI_API_KEY")
        if not api_key:
            print("Please set the GEMINI_API_KEY environment variable")
            exit(1)
            
        scanner = VulnerabilityScanner(api_key)
        
        # Example vulnerable Python code
        code = """
import os
import subprocess

def process_user_input(user_input):
    # Vulnerable to command injection
    os.system("echo " + user_input)
    
    # Vulnerable to code injection
    result = eval(user_input)
    
    # Vulnerable to SQL injection
    query = "SELECT * FROM users WHERE username = '" + user_input + "'"
    
    return result

def read_file(filename):
    # Potential path traversal
    with open(filename, 'r') as f:
        return f.read()
        
# Insecure password storage
PASSWORD = "admin123"
        """
        
        # Scan the code
        results = scanner.scan_code(code, "python")
        
        # Print results
        print("\nVulnerability Scan Results:")
        print(f"Vulnerabilities found: {results['vulnerabilities_found']}")
        print("\nQuick Scan Results:")
        for vuln in results['results']['quick_scan_results']:
            print(f"Line {vuln['line']}: {vuln['type']} - {vuln['code']}")
        
        print("\nDeep Scan Results:")
        print(results['results']['ai_analysis'])
        
    except Exception as e:
        print(f"Error: {e}")
